{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9ec582",
   "metadata": {},
   "source": [
    "# Excercise Notebook: Binary Text Classification with LIME\n",
    "\n",
    "## Assignment Description: Explainable Text Classification with LIME\n",
    "\n",
    "#### In this assignment, you will be introduced to the concept of explainable AI using Python. You will get hands-on experience with the LIME (Local Interpretable Model-Agnostic Explanations) algorithm and Random Forest Classifier.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. Load the 20 Newsgroups dataset: This dataset is a collection of approximately 20,000 newsgroup documents, partitioned across 20 different newsgroups. You will be working with a subset of this data, specifically focusing on the 'alt.atheism' and 'soc.religion.christian' categories.\n",
    "\n",
    "     **Tip** - **Loading the 20 Newsgroups dataset**: This is a well-known dataset available in sklearn. You can find more information and the necessary functions to load this dataset in the sklearn.datasets documentation ([Click here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)), specifically the fetch_20newsgroups function and its parameters (e.g. \"subset\" and \"categories\" parameter).\n",
    "\n",
    "\n",
    "2. Preprocess the data: You will use sklearn.feature_extraction.text.TfidfVectorizer to convert the raw documents into TF-IDF features. You need to transform both the training and the test datasets.\n",
    "\n",
    "     **Tip** - **Preprocessing the data**: The TfidfVectorizer function from sklearn.feature_extraction.text is used in this step. This function is well-documented in sklearn's feature extraction documentation ([Click here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)). It is essential to understand the parameters and the output of this function.\n",
    "\n",
    "\n",
    "3. Train a Random Forest Classifier: You will use sklearn.ensemble.RandomForestClassifier to train a model on the preprocessed training data. Random Forest is a powerful ensemble learning method that operates by constructing multiple decision trees during training and outputting the class that is the mode of the classes or the mean prediction of the individual trees.\n",
    "\n",
    "      **Tip** - **Training a Random Forest Classifier**: The RandomForestClassifier is a part of the ensemble module of sklearn. The official sklearn documentation provides a comprehensive explanation and examples for this classifier (click here: [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)).\n",
    "\n",
    "\n",
    "4. Use the LIME algorithm to explain the predictions: LIME is a novel algorithm that can explain the predictions of any classifier or regressor in a faithful way, by approximating it locally with an interpretable model. You need to use the LimeTextExplainer to explain the prediction of a test document of your choice (here we are using document with index 83). Finally, you are required to display the explanation using show_in_notebook() function.\n",
    "\n",
    "    **Tip** - **Using the LIME algorithm to explain the predictions**: LIME is a separate package for Python, and it has its own dedicated documentation which explains how to use the LimeTextExplainer among other things ([Checkout the documentation here](https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_text)). Make sure to understand the parameters and the output of the explain_instance function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae14395a",
   "metadata": {},
   "source": [
    "## Import the specific python modules needed for the excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c584265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852aa3c",
   "metadata": {},
   "source": [
    "## Load the 20 newsgroups training and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1245801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6ecba",
   "metadata": {},
   "source": [
    "## Now is your turn... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
