{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc81c97",
   "metadata": {},
   "source": [
    "# Excercise Notebook: Image Classification with LIME\n",
    "\n",
    "## Assignment Description: Explainable AI with LIME for Image Classification\n",
    "\n",
    "#### In this assignment, you will be introduced to the concept of Explainable AI using Python. You will get hands-on experience with the LIME (Local Interpretable Model-Agnostic Explanations) algorithm.\n",
    "\n",
    "Your task is to:\n",
    "\n",
    "1. **Load the pretrained InceptionV3 model**: This model, trained on the ImageNet dataset, can classify images into 1000 different categories. Keras provides a simple way of loading this model.\n",
    "\n",
    "     **Tip**: You can find more about the InceptionV3 model in the Keras documentation. Look for [keras.applications.inception_v3.InceptionV3](https://keras.io/api/applications/inceptionv3/).\n",
    "\n",
    "\n",
    "2. **Prepare the image**: This involves loading the image, resizing it to match the input size of InceptionV3 model (299 x 299), and preprocessing it using the InceptionV3 preprocessing function.\n",
    "\n",
    "     **Tip**: The Keras **load_img** and **img_to_array** functions can be used for loading and converting images. You can find their usage in the [Keras preprocessing image module documentation](https://keras.io/api/data_loading/image/). The **preprocess_input** function is also important and its usage can be found in the [Keras InceptionV3 documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/inception_v3/preprocess_input). The **preprocess_input** function is used to prepare your image data to be fed into a neural network. Each pre-trained model provided in the Keras library expects the input data (image) to be preprocessed in a particular way. This function applies this specific preprocessing.\n",
    "\n",
    "\n",
    "3. **Visualize the image & Make predictions**: Display the image to have a visual understanding of the data. Use the pretrained model to make predictions and print the top predictions.\n",
    "\n",
    "      **Tip**: The Matplotlib library can be used for visualization in Python. You can check the **imshow** function in the [Matplotlib Pyplot module documentation](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html). The **predict function** is a standard prediction function of any model in Keras. You can find it in the [Keras Model documentation](https://keras.io/api/models/model_training_apis/). The **decode_predictions** function can be used to convert the raw output of the model, which is typically a multi-dimensional probability distribution over the classes, into human-readable labels and their associated probabilities. The **decode_predictions** function is specific to models trained on ImageNet and can be found in the [Keras Applications Imagenet Utils documentation](https://www.tensorflow.org/api_docs/python/tf/keras/applications/imagenet_utils/decode_predictions).     \n",
    "\n",
    "\n",
    "4. **Use the LIME algorithm to explain the prediction**: Create an instance of the **LimeImageExplainer**, and call the **explain_instance** method. This method generates an explanation for the top predicted classes.\n",
    "\n",
    "    **Tip**: The LIME package has its own documentation which explains how to use the **LimeImageExplainer** and its methods ([See here](https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_image)). \n",
    "    \n",
    "    **The LIME package is used to explain the predictions of a machine learning model. For this, we are particularly interested in the LimeImageExplainer class and its method explain_instance.**\n",
    "\n",
    "    **LimeImageExplainer**: This class allows you to explain predictions on image data. Create an instance without any arguments.\n",
    "\n",
    "    * **explain_instance**: This method generates explanations for the predictions on an instance. Here are some important arguments you should be aware of:\n",
    "\n",
    "        * image: This is your input image that you want to explain.\n",
    "        * classifier_fn: This is your model prediction function that takes images and returns prediction probabilities.\n",
    "        * top_labels: The number of top labels (classes) to explain.\n",
    "        * hide_color: The color for the hidden parts of the image. When parts of the image are not explained, they are hidden and replaced with this color.\n",
    "        * num_samples: The number of perturbations to create. (e.g. use 1000 for this assignment)\n",
    "\n",
    "Each of these arguments can greatly affect the explanations generated by LIME, so it's important to understand what they do.\n",
    "    \n",
    "    \n",
    "5. **Visualize the explanation**: Retrieve the explanation image and mask from the LIME explanation and visualize it using the mark_boundaries function from the skimage.segmentation module.\n",
    "\n",
    "    **Tip**: After creating the explanations, you need to visualize them. This can be done using the get_image_and_mask method and the mark_boundaries function.\n",
    "\n",
    "    * **get_image_and_mask**: This method of the Explanation object returned by LIME generates an image and a mask. Here are the important arguments:\n",
    "        * label: The label (class) you want to explain.\n",
    "        * positive_only: If True, only show the superpixels that contribute positively to the class. Otherwise, show both positive and negative contributions.\n",
    "        * num_features: The number of superpixels to include in the explanation.\n",
    "        * hide_rest: If True, hide the rest of the image and only show the explanatory superpixels.\n",
    "     \n",
    "    * **mark_boundaries**: This function from the skimage.segmentation module ([skimage documentation](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.mark_boundaries)) takes an image and a mask, and returns an image with the mask boundaries marked. This allows you to clearly see the superpixels identified by LIME.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543441ae",
   "metadata": {},
   "source": [
    "## Import the specific python modules needed for the excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32dca1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "from keras.applications import inception_v3 as inc_net\n",
    "import keras.utils as image\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca731f51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 20:45:43.849619: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-03 20:45:43.849732: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n"
     ]
    }
   ],
   "source": [
    "#Initiate the Inception Model\n",
    "inet_model = inc_net.InceptionV3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e0f04",
   "metadata": {},
   "source": [
    "## Now its your turn..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
